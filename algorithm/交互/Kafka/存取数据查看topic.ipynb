{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dc_abnormal_data': TopicMetadata(dc_abnormal_data, 3 partitions),\n",
       " 'dc_test_event_forward': TopicMetadata(dc_test_event_forward, 3 partitions),\n",
       " 'rum_data': TopicMetadata(rum_data, 3 partitions),\n",
       " 'dc_databuff_process': TopicMetadata(dc_databuff_process, 3 partitions),\n",
       " 'dc_databuff_dfni_reqs': TopicMetadata(dc_databuff_dfni_reqs, 3 partitions),\n",
       " 'dc_gw_cmdb': TopicMetadata(dc_gw_cmdb, 3 partitions),\n",
       " 'dc_databuff_log': TopicMetadata(dc_databuff_log, 3 partitions),\n",
       " 'dc_abnormal_control': TopicMetadata(dc_abnormal_control, 1 partitions),\n",
       " 'dc_aggs_policy_event': TopicMetadata(dc_aggs_policy_event, 3 partitions),\n",
       " 'dc_agg_event': TopicMetadata(dc_agg_event, 3 partitions),\n",
       " '__consumer_offsets': TopicMetadata(__consumer_offsets, 50 partitions),\n",
       " 'dc_databuff_container': TopicMetadata(dc_databuff_container, 3 partitions),\n",
       " 'dc_databuff_resource': TopicMetadata(dc_databuff_resource, 3 partitions),\n",
       " 'dc_fault_event': TopicMetadata(dc_fault_event, 3 partitions),\n",
       " 'dc_databuff_k8s': TopicMetadata(dc_databuff_k8s, 3 partitions),\n",
       " 'dc_databuff_trace': TopicMetadata(dc_databuff_trace, 3 partitions),\n",
       " 'dc_rca': TopicMetadata(dc_rca, 3 partitions),\n",
       " 'dc_databuff_checkrun': TopicMetadata(dc_databuff_checkrun, 3 partitions),\n",
       " 'dc_databuff_dfni_req_stats': TopicMetadata(dc_databuff_dfni_req_stats, 3 partitions),\n",
       " 'dc_event': TopicMetadata(dc_event, 3 partitions),\n",
       " 'dc_monitor_alarm_notify': TopicMetadata(dc_monitor_alarm_notify, 3 partitions),\n",
       " 'dc_databuff_metric': TopicMetadata(dc_databuff_metric, 3 partitions)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient\n",
    "bootstrap_servers = \"192.168.50.110:19092\"  # 定义Kafka broker的地址\n",
    "admin_client = AdminClient({\"bootstrap.servers\": bootstrap_servers}) # 创建一个AdminClient对象\n",
    "topics_list = admin_client.list_topics().topics  # 调用list_topics()方法获取主题列表\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "bootstrap_servers = \"192.168.50.110:19092\"  # 定义Kafka broker的地址\n",
    "admin_client = AdminClient({\"bootstrap.servers\": bootstrap_servers}) # 创建一个AdminClient对象\n",
    "\n",
    "# 定义要创建的主题名称和配置\n",
    "topic_name = \"my_topic\"\n",
    "num_partitions = 1\n",
    "replication_factor = 1\n",
    "\n",
    "# 创建一个NewTopic对象\n",
    "new_topic = NewTopic(\n",
    "    topic=topic_name,\n",
    "    num_partitions=num_partitions,\n",
    "    replication_factor=replication_factor\n",
    ")\n",
    "\n",
    "# 调用create_topics()方法创建主题\n",
    "admin_client.create_topics([new_topic])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = {}\n",
    "config['bootstrap_servers'] = \"192.168.50.110:19092\"\n",
    "config['event_topic'] = 'test'\n",
    "config['offset'] = 'earliest'\n",
    "config['groupid'] = 'test01'\n",
    "new_topic = {}\n",
    "new_topic['topic_name'] = 'test'\n",
    "new_topic['partitions'] = 1\n",
    "new_topic['replication'] = 1\n",
    "config['new_topic'] = new_topic\n",
    "with open('./config.json', 'w') as f:\n",
    "    json.dump(config,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient\n",
    "\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "class Topic():\n",
    "    def __init__(self):\n",
    "        self.admin_client = AdminClient({\"bootstrap.servers\": config['bootstrap_servers']}) # 创建一个AdminClient对象\n",
    "    \n",
    "    def get_topic(self):\n",
    "        topics_list = self.admin_client.list_topics().topics  # 调用list_topics()方法获取主题列表\n",
    "        return topics_list\n",
    "    \n",
    "    def create_topic(self):\n",
    "        new_topic = NewTopic(topic = config['new_topic']['topic_name'], \n",
    "                             num_partitions =  config['new_topic']['partitions'], \n",
    "                             replication_factor = config['new_topic']['replication'])\n",
    "        admin_client.create_topics([new_topic])\n",
    "        \n",
    "    def main(self):\n",
    "        if config['new_topic']['topic_name'] in self.get_topic().keys():\n",
    "            return True\n",
    "        else:\n",
    "            self.create_topic()\n",
    "            print('创建 topic 成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "import json\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "class getdata():\n",
    "    def __init__(self):\n",
    "        self.c = Consumer({\n",
    "            'bootstrap.servers':config['bootstrap_servers'], # kafka所在ip地址\n",
    "            'group.id':config['groupid'],\n",
    "            'enable.auto.commit':True, # 是否自动提交offset，设为True时，每隔一段时间就会提交一次offset\n",
    "            'default.topic.config':{\n",
    "                'auto.offset.reset':config['offset']\n",
    "            }  \n",
    "        })\n",
    "    \n",
    "    def main(self):\n",
    "        self.c.subscribe([config['event_topic']]) # 为consumer分配分区\n",
    "        # 没有break会不停的取数据\n",
    "        while True:\n",
    "            msg = self.c.poll(100)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            else:\n",
    "                topicMsg = msg.topic()\n",
    "                message = json.loads(msg.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print('Message delivery failed: {}'.format(err))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "class inputdata():\n",
    "    def __init__(self):\n",
    "        self.publisher = Producer({'bootstrap.servers': config['bootstrap_servers']})\n",
    "    \n",
    "    def main(self):\n",
    "        for i in range(10000000):\n",
    "            data = {'timestamp': time.time(), 'nums': i}\n",
    "            publisher.poll(1)\n",
    "            publisher.produce(config['event_topic'], json.dumps(data).encode('utf-8'),partition = 1, callback=delivery_report, timestamp = int(data['timestamp'])*1000)\n",
    "            publisher.flush()\n",
    "inputdata().main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"timestamp\": 1686119047.8197303, \"nums\": 1}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "data = {'timestamp': time.time(), 'nums': 1}\n",
    "json.dumps(data).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1686119076.929917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
